---
title: "`auto_rate()`"
output:
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{automation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, echo = F}
library(knitr) # load knitr to enable options
library(respR) # load respR

opts_chunk$set(collapse = TRUE, comment = "#>", cache = FALSE, tidy = TRUE,
  highlight = TRUE, fig.width = 7.1, fig.height = 6)
```

## Introduction

The function `auto_rate()` uses rolling regressions to automatically determine the *maximum*, *minimum*, or *most linear* sections of an oxygen time-series over a specific sampling window. In addition, to detect linear sections of the data an additional kernel density estimate is performed on the rolling regression output, and the kernel bandwidth, which is 
and the optimal bandwidth is then used to re-sample overlapping rolling regression windows as a whole.

<!-- ### Working in the Tidyverse -->

<!-- `respR` integrates nicely in the [Tidyverse](https://www.tidyverse.org/), specifically with `dplyr` functions e.g. `select()`, `filter()` and `mutate()`, and `magrittr` pipe operators ("`%>%`") to clearly express workflows in an organised sequence. For more information about using pipes in particular, see the ["Pipes" chapter](http://r4ds.had.co.nz/pipes.html) in the online R for Data Science book. -->

<!-- We load the data, `sardine.rd`, which contains approximately 2.1 hours (7,513 data points) of a single respirometry experiment. -->

<!-- ```{r} -->
<!-- library(respR) -->
<!-- data("sardine.rd") -->
<!-- ?sardine.rd # run this to see notes about the dataset -->
<!-- ``` -->


```{r, echo = F}
library(DiagrammeR)
grViz("
digraph a_nice_graph {

# node definitions with substituted label text

node [fontname = Helvetica, shape = circle]        
rd [label = 'Raw Data']

node [fontname = Helvetica, shape = rectangle]        
rr [label = '1. Rolling linear regression']
kd [label = '2. Kernel density\nestimates']
ar [label = '4. Rank']
fi [label = '5. Filter']
re [label = '3. Bin resampling']

node [fontname = Menlo, shape = none]
li [label = 'linear']
mm [label = 'max, min']
in [label = 'interval']

# edge definitions with the node IDs

rd -> rr -> ar -> mm
rr -> kd -> re -> ar -> li
rr -> fi -> in

}")
```


### 1. Rolling linear regression

The use rolling linear regression techniques to automatically estimate metabolic parameters is not common in the current literature. Yet the technique is an ubiquitous tool in financial statistitical analysis as it can easily and automatically assess model stability. Since respirometry data also relies on the key assumption that regression coefficients over a rolling window are constant over time (i.e. data is linear), rolling regression is an ideal analytical technique to assess data linearity and detect common metabolic parameters more accurately than commonly used empirical methods. 

A rolling regression performs *all* possible ordinary least-squares (OLS) linear regressions $(y = \beta X + \epsilon)$ of a specific width across a data series, and is expressed as: $$y_t(n) = X_t(n) \beta (n) + \epsilon_t(n), \ t = n,\ ...,\ T$$ where $n$ is the window of width $n < T$, the total length of the dataset, $y_t(n)$ is the vector of observations on the response, $X_t(n)$ is the matrix of explanatory variables, $\beta (n)$ is a vector of regression parameters and $\epsilon_t(n)$ is a vector of error terms.

By default, `auto_rate()` performs the rolling regression at a fixed window, $n$, that is one-fifth of the total length of the number of data points (`by = "row"`) or total time elapsed (`by = "time"`). However, that value can be modified using the `width` argument (e.g. as a proportion, `width = 0.1`; as a fixed value, `width = 600`).

If `auto_rate()` is used to simply estimate maximum, minimum or interval rates, no further transformation of the data is necessary. The regression coefficients are automatically filtered and ranked to produce the parameter of interest.

<!-- Any value less than 1 is automatically assumed to define a proportion, and is multiplied by the total number of samples (or total time elapsed) in the data before it is used.  -->


### 2. Kernel density estimates

<!-- The analysis of time-series data in both fields rely on the *same* key assumption that their parameters are constant over time (i.e. data is linear).  -->
When paired with kernel density estimation, the process of detecting linear stability and identifying the most linear (stable) sections of respirometry data can be automated.



We take advantage of the fact that a truly linear dataset should be reflected by a consistently stable (i.e. flat) rate over the rolling window. If the rate changes at some point during the sampling, then the variability should be detected in the rolling estimates. Consequently, one may empirically select stable regions in the dataset by observing the rolling regression data and selecting regions that are stable. 

We standardise and automate this process using Gaussian Kernel Density Estimation (KDE), a powerful technique that takes an unsupervised approach to detect linear regions of a dataset. Because KDE is a non-parametric estimator, it determines the density of the most common A linear

Kernel density estimation (KDE) is, in simple terms, an algorithm that models the probability distribution of a continuous random variable. When used on a rolling regression output of $\beta$ coefficients (i.e. calculated rates)

### 3. Bin resampling

### 4. Rank

### 5. Filter

## Examples

## Comparison to other methods and packages {#compare}

