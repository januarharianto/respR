---
title: "select_rate: Exploring and filtering results"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
vignette: >
  %\VignetteIndexEntry{select_rate: Exploring and filtering results}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, echo = F}
library(knitr) # load knitr to enable options
library(respR) # load respR

opts_chunk$set(collapse = TRUE, 
               comment = "#>", 
               cache = FALSE, 
               tidy = FALSE, 
               highlight = TRUE, 
               fig.width = 10, 
               fig.height = 5,
               fig.align = "center",
               R.options = list(scipen = 999, 
                                digits = 3))
```

## Introduction {#adjintro}

Depending on the type of experiment or the functions used, `respR` analyses can return multiple rates from a single dataset. Once these are converted to final units in `convert_rate()`, this can leave a user with an often large and potentially confusing array of different rates from different, or even the same, regions of the data. The `select_rate()` function is designed to allow `convert_rate` results to be explored, reordered, and filtered to arrive at a final reportable rate. 

Having multiple rates can be a result of several analyses. The `auto_rate()` function uses machine learning techniques to automatically detect the most linear regions of a dataset, as well as being able to fit a rolling regression of a specified width over the entire dataset and order the results in various ways. Both of these can return hundreds to thousands of rates. `calc_rate()` can also return multiple rates depending on the inputs. `calc_rate.int()` returns a single rate from every replicate in an intermittent-flow respirometry dataset, so there will be as many rates as there are replicates.

`select_rate` helps explore and filter `convert_rate` results by selecting rates according to various criteria. For example, extracting only positive or negative rates, only the highest or lowest rates by number or percentile, those above a particular R-squared, only those from certain data regions, and numerous other methods that allow advanced filtering of rates. This allows for application of consistent rate selection criteria and reporting of results. Several methods also allow the results to be reordered by that metric, which can be useful in several situations. 

Note that generally speaking, for large datasets we recommend using `subset_data()` and running analyses on the subset(s) of the data you are interested in, rather than extract rates across the whole dataset and relying on `select_rate` to filter it afterwards. 

## Selection methods

The function includes a wide array of criteria by which `convert_rate` results can be filtered. The full list can be seen in the [Details]() section of the help file. We will run through a few specific examples below. Multiple selection criteria can be applied by saving the output and processing it through the function multiple times with different criteria, or alternatively via piping (`%>%` or `|>`). See examples below. 

## Rank column {#rankcol}

For most selection operations, the summary table `$rank` column is important in keeping track of results. The `$rank` column is context-specific, and what it represents depends on the type of experiment analysed or the function used to determine the rates. If numeric values were converted, it is the order in which they were entered. Similarly, if `calc_rate` was used to determine multiple rates, it is the order as entered using `from` and `to`. For `auto_rate` it relates to the `method` input. For example it indicates the kernel density ranking if the `linear` method was used, the ascending or descending ordering by absolute rate value if `lowest` or `highest` were used, or the numerical order if `minimum` or `maximum` were used. For intermittent-flow experiments analysed via `calc_rate.int` it indicates the replicate number. The `$rank` column can be used to keep track of selections or reordering because the original rank value will be retained unchanged through these operations. The original order can always be restored through reordering by rank using `method = "rank", n = NULL`. 

## Plot {#plotconv}

As of [v2.1](https://januarharianto.github.io/respR/articles/whatsnew.html), `convert_rate` has new plotting functionality that help explore the results and view the result of selection or reordering. This can be used by passing `plot = TRUE` in the `convert_rate` call (default is `FALSE`). Alternatively the output object can be passed or piped to `plot()` after processing in `select_rate`. 

There are three ways of plotting the results. The default is `type = "grid"`, which plots each rate in order in the context of the entire data timeseries up to a maximum of 20. These can be selected using `pos`, which represents rows of the summary table with the default being `pos = 1:20`.

```{r fig.keep='none', results='hide', message=FALSE, echo = FALSE}
sard <- 
  inspect(sardine.rd) |> 
  auto_rate() |> 
  adjust_rate(by = -0.00006) |> 
  convert_rate(oxy.unit = "%Air",
               time.unit = "sec",
               output.unit = "mg/h/kg",
               volume = 12.3,
               mass = 0.0477,
               S = 35, 
               t = 14.8,
               p = 1.013) 
```

```{r results='hide'}
plot(sard)
```

This lets you see where each rate occurs within the dataset, with the converted rate value in the title. The values on the axes - time (bottom), row (top), and oxygen (left) - are in the units of the original raw data. 

The second option is `type = "rate"`. This plots the entire data timeseries on the upper plot, and on the lower plot the output rate values in the chosen output units. Each rate is plotted against the middle of the region used to determine it. 

```{r results='hide'}
plot(sard, type = "rate")
```

The final option is `type = "overlap"`. This plot helps with understanding how rates are distributed across the dataset, particularly how they may overlap. The top plot is the entire data timeseries. In the lower plot every rate regression in `$summary` is represented by a line showing its location within the timeseries. The y-axis represents the position (i.e. row) of the summary table descending from top to bottom. If no reordering or selection has been performed, this will be equivalent to the `$rank` column. See [above section](#rankcol) for what the rank may represent, but note as reordering or selection is performed rank and summary table position will not necessarily be equivalent. 

```{r results='hide'}
plot(sard, type = "overlap")
```

Additional inputs can be passed, such as `pos`, `quiet`, `legend`, and `highlight`. See `help("select_rate")`. 

## Examples

These are brief run-throughs of a few example selection or reordering operations. More practical examples can be seen in `vignette("intermittent_long")`. These are not recommendations for how you should conduct your own analyses, or for what selection criteria are appropriate for particular datasets, they are simply examples to demonstrate the functionality. 

### `auto_rate` `"linear"` results

Generally speaking the `linear` method is very good at identifying linear regions, and typically the top result is the most appropriate to report. However, it depends on the aims of your experiment and there may be situations where we would want to further refine the returned results. 

We'll use the `sardine.rd` dataset, and let's say we are interested in extracting a standard metabolic rate (SMR), that is a basal or maintenance rate. Generally this is the lowest rate observed, and usually that requires defining the duration over which the rate is sustained when we extract it, and how to choose this duration is arguably not objective. The `linear` method has a benefit here, in that it will identify consistently maintained rates, including the lowest consistently maintained rates. However, it will also identify all consistently maintained rates in the dataset, so the lowest is not necessarily the top-ranked one. 

We'll `inspect` the data, pipe the result to `auto_rate` using the default inputs of the `"linear"` method and `width = 0.2`, then adjust the rates for background (using an invented value as an example), then convert the rates to our final units.   

```{r fig.keep='last', results='hide', message=FALSE}
sard <- 
  inspect(sardine.rd) |> 
  auto_rate() |> 
  adjust_rate(by = -0.00006) |> 
  convert_rate(oxy.unit = "%Air",
               time.unit = "sec",
               output.unit = "mg/h/kg",
               volume = 12.3,
               mass = 0.0477,
               S = 35, 
               t = 14.8,
               p = 1.013) 
```

This is large dataset, from a relatively long experiment of over 2 hours. The `auto_rate` analysis has identified 39 linear regions, of which the above plot is the highest ranked one, or most linear according to the kernel density analysis. This does not mean it's the lowest rate, but is generally the most consistently maintained one. 

Let's look at the `convert_rate` summary table. The version printed to the console via `summary()` is a condensed version, but the output contains an extended summary table with all rate regression parameters and data locations, adjustments (if applied), units, and more, which is what we will examine here. 

```{r}
sard$summary
```

Obviously this is a lot of information to digest. The `rate.output`, which is the primary output we are interested in, varies in value by quite a lot. The r-squared of the regressions is fairly variable. The linear regions also come from all over the dataset as can be seen by looking at the time or row columns. It might be difficult to know how to handle this many results and arrive at a final reportable rate. 

If we are looking for the lowest linear rate, the top ranked result here is actually a very good one! It is amongst the lowest rates (only 2 in rows 8 and 9 are lower), has a high r-squared, and is sustained over a large region of the data. This would probably be perfect appropriate to report as the SMR, however we'll proceed with selection to show how these criteria can be applied, and then these could be applied to other experiments. 

#### Plot

We can use the `convert_rate` plotting functionality to get a better idea of rate values and how they are distributed. We'll look at both the rate value plot and the overlap plot.

```{r results='hide'}
plot(sard, type = "rate")
plot(sard, type = "overlap")
```

We can see the rates are higher at the start of the dataset, after which they stabilise. From the overlap plot we can see many of the linear regions substantially overlap and are essentially from the same regions of the data. Some are even completely contained within others. We don't need to keep all of these different results.  

#### Selection of rates

`select_rate` allows us to select out only the results that meet certain criteria. 


#### Additional selection criteria

Let's apply a couple of additional criteria. 

Let's say we are only interested in rate results with an r-squared above 0.95, and also that we are only interested in rates which are sustained for at least 30 minutes (1800s). We can apply all three of our selection criteria by using pipes. 

```{r fig.keep='last', message=FALSE}
sard |> 
  select_rate(method = "rsq", n = c(0.95,1)) |>
  select_rate(method = "duration", n = c(1800, Inf)) |>
  select_rate(method = "overlap", n = 0.9) |>
  overlap.p() |>
  summary()
```

Now we are left with only three results. We could choose to select the highest ranked remaining one as our RMR, or maybe average the remaining three. The important point to take from this is that the same selection criteria can be consistently applied and documented across multiple analyses. 

#### Reporting the result

`select_rate` allows you to apply very specific selection criteria in a specific priority order. Because of this is it straightforward to report the analysis in clear language. We might report the above analysis in just a short passage in the methods like this:

*"Data was analysed using the R package `respR` (Harianto et al. 2019). The auto_rate "linear" method was used to automatically identify linear regions of the data. RMR was defined as the lowest of these rates with r-squared above 0.95 sustained for at least 30 minutes."*


### `auto_rate` `"lowest"` results

Let's use the `sardine.rd` dataset again, and let's say we are interested in extracting a standard metabolic rate, that is the lowest routine rate, one which may be representative of basal maintenance metabolism.  

There are a number of approaches we could take using a combination of `auto_rate` and `select_rate`. Here we'll cover two of them: 

- using the `linear` method and selecting from amongst these linear regions to find the lowest

- run `auto_rate` with `method = "lowest"` and a fixed `width` and select the ones we are interested in while applying some additional criteria

#### `method = "lowest"`

The SMR rates we extracted above occur over durations of 45 minutes to nearly an hour. But maybe we want to standardise our analyses and comparisons of different specimens by defining our SMR as the lowest rate across a specific duration, for example 20 minutes. We can use the `auto_rate` `method = "lowest"` to output all rates of this specific `width` and order them from lowest to highest value. Then we can apply some additional selection criteria.

Here we do a rolling regression of 20 minutes (`1200` seconds) `width` in the `"time"` metric. 

```{r fig.keep='last', results='hide', message=FALSE}
sard <- inspect(sardine.rd) |> 
  auto_rate(method = "lowest", width = 1200, by = "time") |>
  adjust_rate(by = -0.00006) |> 
  convert_rate(oxy.unit = "%Air",
               time.unit = "sec",
               output.unit = "mg/h/kg",
               volume = 12.3,
               mass = 0.0477,
               S = 35, 
               t = 14.8,
               p = 1.013) |>
  summary()
```

The function has fit every regression of 1200s width and ranked them in order of absolute rate value from lowest to highest. The plot shows the top ranking result, in this case the very lowest rate. We may not necessarily want to use this however. In this case it has a relatively low r-squared compared to others (we're not showing the full summary table but it ranges from around 0.88 to 0.95). 

Let's look at the `overlap.p` output.

```{r fig.keep='last', results='hide', message=FALSE}
sard |> 
  overlap.p() 
```

This plot is perhaps difficult to understand at first, but should beciome clear. The lowest rates are at the top of the summary table, so the plot shows most of these high ranking results are towards the end of the dataset. By contrast, high rates are at the start. This plot is essentially the rolling rate (panel 4) of the `auto_rate` plot just above flipped vertically. See how the lowest rates occur around timepoint 6000 in both. 

We are looking for lowest rates, so we don't need to keep any rates before around timepoint 3000. We can remove those using `time_omit` to input a range to omit. Let's also only keep those with r-squared above 0.9.

```{r fig.keep='last', message=FALSE}
sard |>
  select_rate(method = "rsq", n = c(0.9, 1)) |>
  select_rate(method = "time_omit", n = c(0,3000)) |>
  overlap.p() |>
  summary()
```

Now we are left with 1854 results, all from a couple of different regions of the data. We'll refine this down further by only taking the 500 lowest of these rates, then removing those which overlap with another by 90% or more. We are doing the `"overlap"` method last because it is *extremely* computationally intensive and the time it takes increases exponentially with the number of results remaining. 

```{r fig.keep='last', message=FALSE}
sard |>
  select_rate(method = "rsq", n = c(0.9, 1)) |>
  select_rate(method = "time_omit", n = c(0,3000)) |>
  select_rate(method = "lowest", n = 500) |>
  select_rate(method = "overlap", n = 0.9) |>
  overlap.p() |>
  summary() |>
  mean()
```

Now we are left with only 3 results, and this time we have piped the results to the mean function to get a final mean rate, which we can [adjust](https://januarharianto.github.io/respR/articles/adjust_rate) and [convert](https://januarharianto.github.io/respR/articles/intermittent_long.html#convert) to units.

#### Selection criteria ordering

Note that the order you apply selection criteria is *extremely important*. Applying the same criteria in a different order can give totally different results. What happens if we repeat the above but take the lowest 500 results first, *then* apply our r-squared range? 

```{r error=TRUE}
sard |>
  select_rate(method = "lowest", n = 500) |>
  select_rate(method = "rsq", n = c(0.9, 1)) 
```

Now we have no results! This is because in the original ordered results, none of the lowest 500 rates had an r-squared above 0.9. 

This demonstrates how selection criteria should be consistently applied in the same priority order across different analyses. 


#### Reporting the result

`select_rate` allows you to apply very specific selection criteria in a specific priority order. Because of this is it extremely easy to report the analysis. We might report the above analysis in just a short passage in the methods like this:

*"Data was analysed using the R package `respR` (Harianto et al. 2019). The `auto_rate` function was used to calculate a rolling regression of 20 minutes across the dataset. SMR was defined as the mean of the lowest rates with r-squared above 0.9."*


## Overlapping results

A notable aspect of the `auto_rate` `linear` method is that due to the machine learning algorithm it can often return multiple linear regions from the same part of a dataset. There is a special selection method to remove some or all of these overlapping rates. See examples below.

One of the selection methods is to remove regressions which overlap. In the `overlap` method, the `n` input indicates the proportional degree of overlap to allow for a result to be retained. For `n = 0` only rates which do not overlap at all, that is share *no* data, are retained. For `n = 1` rates which are entirely contained with another are removed. For `n = 0.5` any regression which shares at least 50% of it's datapoints with another are removed. It performs this analysis working from the bottom of the summary table upwards, so generally lower ranked results are removed first, though bear in mind the results may have been reordered. 
It is recommended this method be used after other selection criteria have been applied, as it is quite aggressive about removing rates, and can be *very* computationally intensive when there are many results.

Here we'll show an example of how it could be used to make `auto_rate` results more manageable. Let's remove all results that share 100% of their datapoints with at least one other. Here we pipe the result to `plot()`.

```{r fig.keep='last', message=FALSE, results='hide'}
sardine.rd |> 
  auto_rate() |>
  convert_rate(oxy.unit = "%Air",
               time.unit = "sec",
               output.unit = "mg/h/kg",
               volume = 12.3,
               mass = 0.0477,
               S = 35, 
               t = 14.8,
               p = 1.013) |>
  select_rate(method = "overlap", n = 1) |>
  plot(type = "overlap")
```

This greatly reduces the number of results, but there is still a substantial overlap between them. Therefore, let's adjust the overlap threshold to 0.9, that is regressions which share 90% or more of data with at least one other are removed. 

```{r fig.keep='last', message=FALSE, results='hide'}
sardine.rd |> 
  auto_rate() |>
  convert_rate(oxy.unit = "%Air",
               time.unit = "sec",
               output.unit = "mg/h/kg",
               volume = 12.3,
               mass = 0.0477,
               S = 35, 
               t = 14.8,
               p = 1.013) |>
  select_rate(method = "overlap", n = 0.9) |>
  plot(type = "overlap")
```

```{r echo = FALSE, fig.keep='none', message=FALSE}
sardine.rd |> 
  auto_rate() |>
  convert_rate(oxy.unit = "%Air",
               time.unit = "sec",
               output.unit = "mg/h/kg",
               volume = 12.3,
               mass = 0.0477,
               S = 35, 
               t = 14.8,
               p = 1.013) |>
  select_rate(method = "overlap", n = 0.9) |>
  summary()
```

This has greatly reduced the number of linear regions, and is a much more manageable set of results.  


## More examples

See `help("select_rate")` for full details of all the selection criteria that can be applied. 

More examples will be added to this page in the near future. 
